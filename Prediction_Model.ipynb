{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAvLstYdAE1-"
   },
   "source": [
    "# Binary Classification of Loan data using Random Forest and Neural Network Learning methods and comparing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3tO7-vC-nBG"
   },
   "source": [
    "## **Importing Libraries to be Used** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlItn8195yGU"
   },
   "outputs": [],
   "source": [
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Setting Warnings to Ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9urch2t0BEtp"
   },
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "HRtnmizt8RW-",
    "outputId": "8d2d1314-4e94-47fc-b985-c0c84a00e817"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c3d1ae6a-ac81-4ecc-bde4-fe21086a5512\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-c3d1ae6a-ac81-4ecc-bde4-fe21086a5512\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving New Arise.csv to New Arise.csv\n"
     ]
    }
   ],
   "source": [
    "#Uploading the CSV file from the Local drive using files from Colab library\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_e66gBo06w2N"
   },
   "outputs": [],
   "source": [
    "#Importing the file and reading into a Pandas Dataframe\n",
    "import io\n",
    "df = pd.read_csv(io.BytesIO(uploaded['New Arise.csv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WgvnLgGzDiqW"
   },
   "source": [
    "## Data Exploration and Analysis:\n",
    "A few things are notable from the table below. Firstly, we need to convert a lot of features into numeric ones later on, so that the machine learning algorithms can process them. Furthermore, we can see that some of the features have widely different ranges, that we will need to convert into roughly the same scale. We can also spot some more features, that contain Null which are missing values but are not empty cells, that we need to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "t1nX6AtTPZiP",
    "outputId": "087ca13d-4761-4a3f-e7b8-bb99a82d3136"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientId</th>\n",
       "      <th>clientIncome</th>\n",
       "      <th>incomeVerified</th>\n",
       "      <th>clientAge</th>\n",
       "      <th>clientGender</th>\n",
       "      <th>clientMaritalStatus</th>\n",
       "      <th>clientLoanPurpose</th>\n",
       "      <th>clientResidentialStauts</th>\n",
       "      <th>clientState</th>\n",
       "      <th>clientTimeAtEmployer</th>\n",
       "      <th>...</th>\n",
       "      <th>dueDate</th>\n",
       "      <th>paidAt</th>\n",
       "      <th>loanAmount</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>loanTerm</th>\n",
       "      <th>max_amount_taken</th>\n",
       "      <th>max_tenor_taken</th>\n",
       "      <th>firstPaymentRatio</th>\n",
       "      <th>Firstpayment</th>\n",
       "      <th>loanDefault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>755398623</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>false</td>\n",
       "      <td>29</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Single</td>\n",
       "      <td>business</td>\n",
       "      <td>Rented</td>\n",
       "      <td>KANO</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-10 06:35:11 UTC</td>\n",
       "      <td>2018-09-04 11:54:00 UTC</td>\n",
       "      <td>16000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>915689736</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>false</td>\n",
       "      <td>25</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Single</td>\n",
       "      <td>business</td>\n",
       "      <td>Rented</td>\n",
       "      <td>LAGOS</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-21 07:13:29 UTC</td>\n",
       "      <td>2018-09-06 04:44:04 UTC</td>\n",
       "      <td>14500</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292629156</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>false</td>\n",
       "      <td>32</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Single</td>\n",
       "      <td>education</td>\n",
       "      <td>Rented</td>\n",
       "      <td>ANAMBRA</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-23 11:00:00 UTC</td>\n",
       "      <td>Null</td>\n",
       "      <td>19500</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>671710636</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>false</td>\n",
       "      <td>28</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Married</td>\n",
       "      <td>business</td>\n",
       "      <td>Own Residence</td>\n",
       "      <td>OSUN</td>\n",
       "      <td>36+</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-08-18 04:21:05 UTC</td>\n",
       "      <td>2018-07-10 11:23:31 UTC</td>\n",
       "      <td>19500</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367769827</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>false</td>\n",
       "      <td>34</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Married</td>\n",
       "      <td>medical</td>\n",
       "      <td>Rented</td>\n",
       "      <td>ONDO</td>\n",
       "      <td>36+</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-08-01 07:31:40 UTC</td>\n",
       "      <td>2018-08-09 06:05:37 UTC</td>\n",
       "      <td>17500</td>\n",
       "      <td>12.5</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clientId  clientIncome incomeVerified  clientAge clientGender  \\\n",
       "0  755398623       52500.0          false         29       FEMALE   \n",
       "1  915689736       52500.0          false         25         MALE   \n",
       "2  292629156       35000.0          false         32         MALE   \n",
       "3  671710636       35000.0          false         28       FEMALE   \n",
       "4  367769827       35000.0          false         34         MALE   \n",
       "\n",
       "  clientMaritalStatus clientLoanPurpose clientResidentialStauts clientState  \\\n",
       "0              Single          business                  Rented        KANO   \n",
       "1              Single          business                  Rented       LAGOS   \n",
       "2              Single         education                  Rented     ANAMBRA   \n",
       "3             Married          business           Own Residence        OSUN   \n",
       "4             Married           medical                  Rented        ONDO   \n",
       "\n",
       "  clientTimeAtEmployer     ...                      dueDate  \\\n",
       "0                    7     ...      2018-09-10 06:35:11 UTC   \n",
       "1                   21     ...      2018-10-21 07:13:29 UTC   \n",
       "2                   29     ...      2018-10-23 11:00:00 UTC   \n",
       "3                  36+     ...      2018-08-18 04:21:05 UTC   \n",
       "4                  36+     ...      2018-08-01 07:31:40 UTC   \n",
       "\n",
       "                    paidAt loanAmount interestRate  loanTerm max_amount_taken  \\\n",
       "0  2018-09-04 11:54:00 UTC      16000         20.0        60                1   \n",
       "1  2018-09-06 04:44:04 UTC      14500         15.0        60                0   \n",
       "2                     Null      19500         15.0        60                0   \n",
       "3  2018-07-10 11:23:31 UTC      19500         15.0        60                1   \n",
       "4  2018-08-09 06:05:37 UTC      17500         12.5        60                1   \n",
       "\n",
       "  max_tenor_taken firstPaymentRatio Firstpayment loanDefault  \n",
       "0               1               0.0            0           0  \n",
       "1               1               0.0            0           0  \n",
       "2               1               0.0            1           1  \n",
       "3               1               0.0            0           0  \n",
       "4               1               0.0            1           0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previewing the Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_bL9XXHEURX"
   },
   "source": [
    "## Dropping Informationless Columns:\n",
    "These are columns which bear singularly repetitive or Irrelevant data which should not be added as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRecQobt3wl7"
   },
   "outputs": [],
   "source": [
    "df.drop(['clientId', 'loanId', 'loanType', 'payout_status', 'declinedDate', 'applicationDate', 'approvalDate', 'dueDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "muZy68ENHREh"
   },
   "source": [
    "## Data Exploration:\n",
    "Combing through the data to view all the data column names, their number of rows and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "ZT21RSgi8-0n",
    "outputId": "ab83daab-fe19-432f-eea6-324ff7428218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159596 entries, 0 to 159595\n",
      "Data columns (total 22 columns):\n",
      "clientIncome                 159596 non-null float64\n",
      "incomeVerified               159596 non-null object\n",
      "clientAge                    159596 non-null int64\n",
      "clientGender                 159596 non-null object\n",
      "clientMaritalStatus          159596 non-null object\n",
      "clientLoanPurpose            159596 non-null object\n",
      "clientResidentialStauts      159596 non-null object\n",
      "clientState                  159596 non-null object\n",
      "clientTimeAtEmployer         159596 non-null object\n",
      "clientNumberPhoneContacts    159596 non-null object\n",
      "clientAvgCallsPerDay         159596 non-null object\n",
      "loanNumber                   159596 non-null int64\n",
      "disbursementDate             159596 non-null object\n",
      "paidAt                       159596 non-null object\n",
      "loanAmount                   159596 non-null int64\n",
      "interestRate                 159596 non-null float64\n",
      "loanTerm                     159596 non-null int64\n",
      "max_amount_taken             159596 non-null int64\n",
      "max_tenor_taken              159596 non-null int64\n",
      "firstPaymentRatio            159596 non-null float64\n",
      "Firstpayment                 159596 non-null int64\n",
      "loanDefault                  159596 non-null int64\n",
      "dtypes: float64(3), int64(8), object(11)\n",
      "memory usage: 26.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qvf7v-LUIV8v"
   },
   "source": [
    "## Data Statistics:\n",
    "Here we can see that about 28% of the clients defaulted on their payments and the average loan amount is about N35000. Also, the maximum number of times a loan was collected is 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "8Uso0eGC2UVq",
    "outputId": "3470ea17-0c19-41b7-9e70-f49b9612541c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientIncome</th>\n",
       "      <th>clientAge</th>\n",
       "      <th>loanNumber</th>\n",
       "      <th>loanAmount</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>loanTerm</th>\n",
       "      <th>max_amount_taken</th>\n",
       "      <th>max_tenor_taken</th>\n",
       "      <th>firstPaymentRatio</th>\n",
       "      <th>Firstpayment</th>\n",
       "      <th>loanDefault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.595960e+05</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "      <td>159596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.083906e+04</td>\n",
       "      <td>33.691847</td>\n",
       "      <td>3.556806</td>\n",
       "      <td>35324.184190</td>\n",
       "      <td>13.331235</td>\n",
       "      <td>85.385599</td>\n",
       "      <td>0.705275</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.097991</td>\n",
       "      <td>0.294268</td>\n",
       "      <td>0.277526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.728033e+04</td>\n",
       "      <td>7.180870</td>\n",
       "      <td>2.471578</td>\n",
       "      <td>27840.824297</td>\n",
       "      <td>4.467938</td>\n",
       "      <td>39.323756</td>\n",
       "      <td>0.455921</td>\n",
       "      <td>0.278325</td>\n",
       "      <td>0.278058</td>\n",
       "      <td>0.455714</td>\n",
       "      <td>0.447779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.500000e+04</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.511621e+04</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25500.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.050000e+05</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>37500.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.925000e+06</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clientIncome      clientAge     loanNumber     loanAmount  \\\n",
       "count  1.595960e+05  159596.000000  159596.000000  159596.000000   \n",
       "mean   9.083906e+04      33.691847       3.556806   35324.184190   \n",
       "std    9.728033e+04       7.180870       2.471578   27840.824297   \n",
       "min    3.000000e+01      18.000000       1.000000   11000.000000   \n",
       "25%    3.500000e+04      28.000000       2.000000   20000.000000   \n",
       "50%    5.511621e+04      33.000000       3.000000   25500.000000   \n",
       "75%    1.050000e+05      38.000000       4.000000   37500.000000   \n",
       "max    3.925000e+06     138.000000      32.000000  500000.000000   \n",
       "\n",
       "        interestRate       loanTerm  max_amount_taken  max_tenor_taken  \\\n",
       "count  159596.000000  159596.000000     159596.000000    159596.000000   \n",
       "mean       13.331235      85.385599          0.705275         0.915374   \n",
       "std         4.467938      39.323756          0.455921         0.278325   \n",
       "min         4.500000      60.000000          0.000000         0.000000   \n",
       "25%        10.000000      60.000000          0.000000         1.000000   \n",
       "50%        12.500000      60.000000          1.000000         1.000000   \n",
       "75%        15.000000      90.000000          1.000000         1.000000   \n",
       "max        20.000000     180.000000          1.000000         1.000000   \n",
       "\n",
       "       firstPaymentRatio   Firstpayment    loanDefault  \n",
       "count      159596.000000  159596.000000  159596.000000  \n",
       "mean            0.097991       0.294268       0.277526  \n",
       "std             0.278058       0.455714       0.447779  \n",
       "min             0.000000       0.000000       0.000000  \n",
       "25%             0.000000       0.000000       0.000000  \n",
       "50%             0.000000       0.000000       0.000000  \n",
       "75%             0.000000       1.000000       1.000000  \n",
       "max             1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmZbN0YdMlqg"
   },
   "source": [
    "## Checking for NaN:\n",
    "This was a check for features with NaN(Not a Number) values which in essence are empty cells. It was discoveed that weren't any from the summary table which can be seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "oUSEuS9Q3Dsp",
    "outputId": "aaab9686-b81e-4936-a6f9-9d1ec355de03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loanDefault</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Firstpayment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incomeVerified</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientAge</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientGender</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total    %\n",
       "loanDefault         0  0.0\n",
       "Firstpayment        0  0.0\n",
       "incomeVerified      0  0.0\n",
       "clientAge           0  0.0\n",
       "clientGender        0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = df.isnull().sum()/df.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzxvDt8nND7D"
   },
   "source": [
    "## Data Preprocessing:\n",
    "Here, I used different methods such as one-hot encoding, label encoding, range setting to categorise the data into groups based on inference after probing into each feature.\n",
    "For binary classification such as client gender, Income verified or classification which had less than 10 classes was label encoded. \n",
    "Some of the features had \"Null\" in them and had to be grouped into the class with the highest occurence.\n",
    "Lambda functions were also assigned in some cases.\n",
    "Lastly, some steps in the data analysis were not shown because it was a repetition of checks done before ( i.e checking the features value_count, unique and description were shown for some but not others) so as to make the notebook less clumsy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DroTU_gVu-G"
   },
   "outputs": [],
   "source": [
    "#Grouping client Income by range. There was also no \"null\" here. \n",
    "data = [df]\n",
    "for dataset in data:\n",
    "    dataset['clientIncome'] = dataset['clientIncome'].astype(int)\n",
    "    dataset.loc[(dataset['clientIncome'] > 0) & (dataset['clientIncome'] <= 50000), 'clientIncome'] = 0\n",
    "    dataset.loc[(dataset['clientIncome'] > 50000) & (dataset['clientIncome'] <= 100000), 'clientIncome'] = 1\n",
    "    dataset.loc[(dataset['clientIncome'] > 100000) & (dataset['clientIncome'] <= 200000), 'clientIncome'] = 2\n",
    "    dataset.loc[ dataset['clientIncome'] > 200000, 'clientIncome'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnCdMpHi760h"
   },
   "outputs": [],
   "source": [
    "#Import of label encoder and applying it \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "df[\"incomeVerified\"] = lb_make.fit_transform(df[\"incomeVerified\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EhjQyWtw-2aC"
   },
   "outputs": [],
   "source": [
    "#Ranging client Age and assigning values to each range \n",
    "data = [df]\n",
    "for dataset in data:\n",
    "    dataset['clientAge'] = dataset['clientAge'].astype(int)\n",
    "    dataset.loc[(dataset['clientAge'] > 17) & (dataset['clientAge'] <= 30), 'clientAge'] = 0\n",
    "    dataset.loc[(dataset['clientAge'] > 30) & (dataset['clientAge'] <= 40), 'clientAge'] = 1\n",
    "    dataset.loc[(dataset['clientAge'] > 40) & (dataset['clientAge'] <= 50), 'clientAge'] = 2\n",
    "    dataset.loc[(dataset['clientAge'] > 50) & (dataset['clientAge'] <= 60), 'clientAge'] = 3\n",
    "    dataset.loc[ dataset['clientAge'] > 60, 'clientAge'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1Q23TWeIQ4u"
   },
   "outputs": [],
   "source": [
    "#It can be seen that the largest client age group was between 18 and 30. There was only one client above 60 which was 138 years old from the describe above and was probably an oversight.\n",
    "df['clientAge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OEIopYbJfX5"
   },
   "outputs": [],
   "source": [
    "#label encoding client Gender\n",
    "df[\"clientGender\"] = lb_make.fit_transform(df[\"clientGender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bobGBJN3Kw-f"
   },
   "outputs": [],
   "source": [
    "#label encoding Marital status\n",
    "df[\"clientMaritalStatus\"] = lb_make.fit_transform(df[\"clientMaritalStatus\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dz9AMPw9M6UA"
   },
   "outputs": [],
   "source": [
    "#label encoding Loan purpose\n",
    "df[\"clientLoanPurpose\"] = lb_make.fit_transform(df[\"clientLoanPurpose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OzEN-xEYpHLA",
    "outputId": "c3eab2de-c7c8-4bce-a77b-1c5e1cb05ce0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rented', 'Own Residence', 'Family Owned', 'Employer Provided',\n",
       "       'Temp. Residence', 'Null'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inquiry into the client residential status feature elements \n",
    "df['clientResidentialStauts'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cmktz5Y_OMWC"
   },
   "outputs": [],
   "source": [
    "#\"Null\" was grouped to Rented because it ws the largest class while others were categorised unique\n",
    "df.loc[df['clientResidentialStauts'] == \"Null\", \"clientResidentialStauts\"] = 0\n",
    "df.loc[df['clientResidentialStauts'] == \"Rented\", \"clientResidentialStauts\"] = 0\n",
    "df.loc[df['clientResidentialStauts'] == \"Employer Provided\", \"clientResidentialStauts\"] = 1\n",
    "df.loc[df['clientResidentialStauts'] == \"Family Owned\", \"clientResidentialStauts\"] = 2\n",
    "df.loc[df['clientResidentialStauts'] == \"Own Residence\", \"clientResidentialStauts\"] = 3\n",
    "df.loc[df['clientResidentialStauts'] == \"Temp. Residence\", \"clientResidentialStauts\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEvkMy8PS_1_"
   },
   "outputs": [],
   "source": [
    "#The states were factorized and each category differentiated with an increment of 1.\n",
    "df['clientState'].describe()\n",
    "\n",
    "df['clientState'] = pd.factorize(df['clientState'], sort=True)[0] + 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "J3Vh5eqfX4OK",
    "outputId": "1dfb584f-fcbc-4773-c224-835b90fe0250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     159596\n",
       "unique        41\n",
       "top          36+\n",
       "freq       87294\n",
       "Name: clientTimeAtEmployer, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A check of the data showed that there was a number string 36+. This had to be adjusted to an integer.\n",
    "df['clientTimeAtEmployer'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYuk0ZkJCGi9"
   },
   "outputs": [],
   "source": [
    "# Null was set to the first category while 36+ to 36. Some values in this column were also negative and had to be converted to positive values. A lambda function was used to accomplish\n",
    "#this and another was set to divide the values by 5 and set their categorical value to the integer value.\n",
    "df.loc[df['clientTimeAtEmployer'] == \"Null\", \"clientTimeAtEmployer\"]= 0\n",
    "df.loc[df['clientTimeAtEmployer'] == \"36+\", \"clientTimeAtEmployer\"]= 36\n",
    "df['clientTimeAtEmployer'] = df['clientTimeAtEmployer'].astype(int).apply(lambda x: -x if x<0 else x)\n",
    "df['clientTimeAtEmployer'] = df['clientTimeAtEmployer'].astype(int).apply(lambda x: (x-1)//5 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIs28C6HJeSE"
   },
   "outputs": [],
   "source": [
    "#The loan amount column was categorised by range of values \n",
    "data = [df]\n",
    "for dataset in data:\n",
    "    dataset['loanAmount'] = dataset['loanAmount'].astype(int)\n",
    "    dataset.loc[(dataset['loanAmount'] > 0) & (dataset['loanAmount'] <= 50000), 'loanAmount'] = 0\n",
    "    dataset.loc[(dataset['loanAmount'] > 50000) & (dataset['loanAmount'] <= 100000), 'loanAmount'] = 1\n",
    "    dataset.loc[(dataset['loanAmount'] > 100000) & (dataset['loanAmount'] <= 150000), 'loanAmount'] = 2\n",
    "    dataset.loc[(dataset['loanAmount'] > 150000) & (dataset['loanAmount'] <= 200000), 'loanAmount'] = 3\n",
    "    dataset.loc[(dataset['loanAmount'] > 200000) & (dataset['loanAmount'] <= 250000), 'loanAmount'] = 4\n",
    "    dataset.loc[(dataset['loanAmount'] > 250000) & (dataset['loanAmount'] <= 300000), 'loanAmount'] = 5 \n",
    "    dataset.loc[ dataset['loanAmount'] > 300000, 'loanAmount'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGvM3T9C62pd"
   },
   "outputs": [],
   "source": [
    "# Loan Term was label encoded since there are only 3 options\n",
    "df[\"loanTerm\"] = lb_make.fit_transform(df[\"loanTerm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixlXE6O47psG"
   },
   "outputs": [],
   "source": [
    "# Interest rates were different and had to be categorised by range \n",
    "data = [df]\n",
    "for dataset in data:\n",
    "    dataset['interestRate'] = dataset['interestRate'].astype(int)\n",
    "    dataset.loc[(dataset['interestRate'] > 0) & (dataset['interestRate'] <= 5), 'interestRate'] = 0\n",
    "    dataset.loc[(dataset['interestRate'] > 5) & (dataset['interestRate'] <= 10), 'interestRate'] = 1\n",
    "    dataset.loc[(dataset['interestRate'] > 10) & (dataset['interestRate'] <= 15), 'interestRate'] = 2\n",
    "    dataset.loc[(dataset['interestRate'] > 15) & (dataset['interestRate'] <= 20), 'interestRate'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8bPmgTaR8tKZ"
   },
   "outputs": [],
   "source": [
    "# Same with first payment ratio\n",
    "data = [df]\n",
    "for dataset in data:\n",
    "    dataset['firstPaymentRatio'] = dataset['firstPaymentRatio'].astype(int)\n",
    "    dataset.loc[(dataset['firstPaymentRatio'] > 0) & (dataset['firstPaymentRatio'] <= 0.2), 'firstPaymentRatio'] = 0\n",
    "    dataset.loc[(dataset['firstPaymentRatio'] > 0.2) & (dataset['firstPaymentRatio'] <= 0.4), 'firstPaymentRatio'] = 1\n",
    "    dataset.loc[(dataset['firstPaymentRatio'] > 0.4) & (dataset['firstPaymentRatio'] <= 0.6), 'firstPaymentRatio'] = 2\n",
    "    dataset.loc[(dataset['firstPaymentRatio'] > 0.6) & (dataset['firstPaymentRatio'] <= 0.8), 'firstPaymentRatio'] = 3\n",
    "    dataset.loc[ dataset['firstPaymentRatio'] > 0.8, 'firstPaymentRatio'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58H3xwOpCj0M"
   },
   "outputs": [],
   "source": [
    "# Two lambda functions were set. The first was to map null to zero then the second was to categorise the values by dividing by 2000.\n",
    "data = [df]\n",
    "zeromap = lambda x: 0 if x == \"Null\" else x\n",
    "split = lambda x: 4 if x>8000 else (x-1)//2000 if x>0 else 0\n",
    "for dataset in data:\n",
    "  dataset['clientNumberPhoneContacts'] = dataset['clientNumberPhoneContacts'].apply(zeromap).astype(int)\n",
    "  dataset['clientNumberPhoneContacts'] = dataset['clientNumberPhoneContacts'].apply(split).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFujDgSZG-8J"
   },
   "outputs": [],
   "source": [
    "# The first lambda function was reused then the second was the same as above except now divided by 40 \n",
    "data = [df]\n",
    "split = lambda x: 4 if x> 160 else (x-1)//40 if x>=1 else 0\n",
    "for dataset in data:\n",
    "  dataset['clientAvgCallsPerDay'] = dataset['clientAvgCallsPerDay'].apply(zeromap).astype(float)\n",
    "  dataset['clientAvgCallsPerDay'] = dataset['clientAvgCallsPerDay'].apply(split).astype(int)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZW5hRp9M501"
   },
   "outputs": [],
   "source": [
    "# Parsing the date string to pandas datetime format then extracting the month were disbursement was made \n",
    "df['disbursementDate'] = pd.to_datetime(df['disbursementDate'], format = \"%Y-%m-%d\")\n",
    "df['disbursementDate'] = df['disbursementDate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "70UohvNvP5DB",
    "outputId": "d76769c4-670c-437e-99b5-bd688fa42047"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: paidAt, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The pandas date time infer datetime function was used due to the format of the date. Null was set to category zero. The day of the week was extracted and weekdays were mapped to zero\n",
    "# while weekends to 1\n",
    "df.loc[df['paidAt'] == \"Null\", \"paidAt\"]= 0   \n",
    "\n",
    "df['paidAt'] = pd.to_datetime(df['paidAt'], infer_datetime_format=True).dt.dayofweek\n",
    "df['paidAt'] = df['paidAt'].apply(lambda x: 0 if x<6 else 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2DRWMnbztRQi"
   },
   "source": [
    "## Building the Machine Learning models:\n",
    "Pre-processing is completed and now the models are going to be built. First is the Random Forest classifier after which comes the Neural Network and there would be a comparison of the two methods. The training set will also be used to compare the algorithms with each other. I also used cross-validation to check the accuracy of the k-folds of the models to check how realistic they are. \n",
    "The SMOTE algorithm was used to balance the classes since the number of non-defaulters were about 3 times larger than the defaulters. The algorithm over-sampled the dafaulters to have an equal number of defaulters and non-defaulters.\n",
    "I did a feature importance check and dropped the two least important features to get a better acuracy.\n",
    "I did used several metrics such as f1 test, recall, precision, confusion matrix, accuracy and oob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsNYg5v51RIk"
   },
   "outputs": [],
   "source": [
    "#The Y variable was set to the label and X to the input features then did a train test split with test size set to 30%\n",
    "Y = df.loanDefault\n",
    "X = df.drop('loanDefault', axis = 1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "WXMHwnZPUqay",
    "outputId": "2efebc9d-3de6-456a-ca34-99f29451f0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 31058\n",
      "Before OverSampling, counts of label '0': 80659 \n",
      "\n",
      "After OverSampling, the shape of train_X: (161318, 21)\n",
      "After OverSampling, the shape of train_y: (161318,) \n",
      "\n",
      "After OverSampling, counts of label '1': 80659\n",
      "After OverSampling, counts of label '0': 80659\n"
     ]
    }
   ],
   "source": [
    "# The SMOTE algorithm was used to balance the classes and can be seen in the new shape of Y_train_res which will be used further on\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(Y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(Y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, Y_train_res = sm.fit_sample(X_train, Y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(Y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(Y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65A4CKwg2ktE"
   },
   "outputs": [],
   "source": [
    "#The random forest is then trained on the training set and its accuracy is checked\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train_res, Y_train_res)\n",
    "\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train_res, Y_train_res)\n",
    "acc_random_forest = round(random_forest.score(X_train_res, Y_train_res) * 100, 4)\n",
    "print(acc_random_forest ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YFRQMHq3DFG"
   },
   "source": [
    "**An accuracy of about 99.5% is very high and this could suggest overfitting but this would be confirmed with the accuracy of the testing set which has been fitted on the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "TI4R-2CP29mE",
    "outputId": "0d25c428-0162-4a4c-b5f6-74ea4c6bd9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.83387057 0.82891148 0.83132904 0.83529631 0.86362509 0.8652368\n",
      " 0.86802628 0.86337714 0.8674064  0.86410415]\n",
      "Mean: 0.8521183251196845\n",
      "Standard Deviation: 0.016273974456636597\n"
     ]
    }
   ],
   "source": [
    "#The model was the cross validated with 10 folds to check for the reliability and accuracy of the model \n",
    "from sklearn.model_selection import cross_val_score\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(rf, X_train_res, Y_train_res, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9dTF_kO5DvW"
   },
   "source": [
    "**The model was scored an average of 85.2% which is very realistic and seems very good to use. The estimates also differ by 1.62% which is really strong.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "colab_type": "code",
    "id": "9S-LO-zy4FxQ",
    "outputId": "9fe54401-a3d1-4280-bda8-54ef0cc00129"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Firstpayment</th>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientState</th>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disbursementDate</th>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientTimeAtEmployer</th>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loanNumber</th>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firstPaymentRatio</th>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientLoanPurpose</th>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientIncome</th>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientResidentialStauts</th>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientAvgCallsPerDay</th>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interestRate</th>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientAge</th>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientMaritalStatus</th>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientGender</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paidAt</th>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_amount_taken</th>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loanTerm</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clientNumberPhoneContacts</th>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incomeVerified</th>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loanAmount</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_tenor_taken</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           importance\n",
       "feature                              \n",
       "Firstpayment                    0.288\n",
       "clientState                     0.109\n",
       "disbursementDate                0.101\n",
       "clientTimeAtEmployer            0.061\n",
       "loanNumber                      0.059\n",
       "firstPaymentRatio               0.043\n",
       "clientLoanPurpose               0.042\n",
       "clientIncome                    0.037\n",
       "clientResidentialStauts         0.036\n",
       "clientAvgCallsPerDay            0.033\n",
       "interestRate                    0.028\n",
       "clientAge                       0.028\n",
       "clientMaritalStatus             0.022\n",
       "clientGender                    0.020\n",
       "paidAt                          0.018\n",
       "max_amount_taken                0.017\n",
       "loanTerm                        0.016\n",
       "clientNumberPhoneContacts       0.015\n",
       "incomeVerified                  0.011\n",
       "loanAmount                      0.009\n",
       "max_tenor_taken                 0.007"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The features were compared based on their level of importance using random forest's feature importance function. The most importnt feature was Firstpayment while the least importnat was\n",
    "# max tenor taken.\n",
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkA9f7Ho4aw0"
   },
   "outputs": [],
   "source": [
    "# The two least important ffeatures were then dropped to boost accuracy\n",
    "df  = df.drop(\"max_tenor_taken\", axis=1)\n",
    "df  = df.drop(\"loanAmount\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s4z_WwZ75KA5",
    "outputId": "37043831-158c-488a-8210-8c63f9d9b2a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.5 %\n"
     ]
    }
   ],
   "source": [
    "# The random forest was then scored again on a training level \n",
    "random_forest = RandomForestClassifier(n_estimators=100, oob_score = True)\n",
    "random_forest.fit(X_train_res, Y_train_res)\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "\n",
    "acc_random_forest = round(random_forest.score(X_train_res, Y_train_res) * 100, 2)\n",
    "print(round(acc_random_forest,4,), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxVX70QlAf4I"
   },
   "source": [
    "**There was a slight increase in acccuracy and could be improved more if other less important features are dropped**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8VmL1FLBYRY"
   },
   "source": [
    "**There is also another way to evaluate a random-forest classifier, which is probably much more accurate than the score that was used before.  The out-of-bag samples to estimate the generalization accuracy. The out-of-bag estimate is as accurate as using a test set of the same size as the training set. Therefore, using the out-of-bag error estimate removes the need for a set aside test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RnP1HJ5a5bdu",
    "outputId": "a3c1b372-5a32-498e-f370-2d823931eef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob score: 85.32 %\n"
     ]
    }
   ],
   "source": [
    "print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4iXFAX1EA9l"
   },
   "source": [
    "**This shows that the training on the test and scoring woould result in 85.32%. This is a pretty good classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIh6HvPtEfCy"
   },
   "source": [
    "A Confusion matrix shows how good the classifier did. True positives and True negatives were about 6 times greater than False positives and False Negatives on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z5sq7GNwNSkF",
    "outputId": "7872cdce-6082-4889-f631-fe5b24a72d18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69541, 11118],\n",
       "       [15555, 65104]])"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = cross_val_predict(random_forest, X_train_res, Y_train_res, cv=3)\n",
    "confusion_matrix(Y_train_res, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "jPjTAq76C7Ok",
    "outputId": "d18b19bf-c522-4ce4-9c72-04bb00e88216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84     80659\n",
      "           1       0.85      0.81      0.83     80659\n",
      "\n",
      "   micro avg       0.83      0.83      0.83    161318\n",
      "   macro avg       0.84      0.83      0.83    161318\n",
      "weighted avg       0.84      0.83      0.83    161318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The precision, f1-score, recall are all shown below.\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_train_res,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHaVEpX1HRTg"
   },
   "source": [
    "### The testing set is now classified on the fit of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_OLvNpob4MbU",
    "outputId": "47dd16cb-d578-496e-ffc2-6539d03cf3ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.02 %\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train_res, Y_train_res)\n",
    "\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "acc_random_forest = round(random_forest.score(X_test, Y_test) * 100, 2)\n",
    "print((acc_random_forest), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHLikfr-HgE1"
   },
   "source": [
    "**It did  much less better than the training set did which will suggest an overfit on the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "HulAL94MPfZZ",
    "outputId": "845df4a2-29fc-4909-ba5c-2aba2621e228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87     34645\n",
      "           1       0.65      0.67      0.66     13234\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     47879\n",
      "   macro avg       0.76      0.77      0.76     47879\n",
      "weighted avg       0.81      0.81      0.81     47879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report on the testing set \n",
    "print('Results on the test set:')\n",
    "print(classification_report(Y_test, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "mOiD2j5g41s5",
    "outputId": "e65e300c-ee0a-4978-cba9-321620e03774"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29897,  4748],\n",
       "       [ 4341,  8893]])"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix on the testing set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, Y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0fBoAkOIME1"
   },
   "source": [
    "### Hyperparameter tuning of the Random Forest Classifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "67nXlkDk6VWz",
    "outputId": "5e573443-d0cb-4f99-fe81-f3babd0c6c7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting the parameters and fitting on the training data and then displaying the best parameters\n",
    "# Also the tuples had to be restricted to a size of two to reduce search iteration time \n",
    "param_grid = { \n",
    "    \"min_samples_leaf\" : [1, 5], \"min_samples_split\" : [10, 16], \"n_estimators\": [300, 700]}\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n",
    "clf.fit(X_train_res, Y_train_res)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UkJ6tN1mI3pZ"
   },
   "source": [
    "**These best parameters are then plugged into the classifier and used to score how well the testing data did**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y2aA9QxmKiUI",
    "outputId": "b84af93a-ec2b-4caf-b2ed-a20f62279eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.42 %\n"
     ]
    }
   ],
   "source": [
    "acc_random_forest = round(clf.score(X_test, Y_test) * 100, 2)\n",
    "print((acc_random_forest), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuVa3RbGJEyl"
   },
   "source": [
    "**The accuracy of the hyper parameter tuned Random forest is relatively better than that of the testing set alone but still less than the oob score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "gnKi_kNkfJq_",
    "outputId": "a602c5cb-496f-46d4-ae04-cb73c0454b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set with hyperparameter tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88     34645\n",
      "           1       0.68      0.75      0.71     13234\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     47879\n",
      "   macro avg       0.79      0.81      0.80     47879\n",
      "weighted avg       0.84      0.83      0.84     47879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the Hyperparameter tuned Random Forest\n",
    "y_prediction = clf.predict(X_test)\n",
    "print('Results on the test set with hyperparameter tuning:')\n",
    "print(classification_report(Y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28gA2iS5KfEF"
   },
   "source": [
    "**This is as good as the classification report of the cross validation set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-d2_zEsLayf"
   },
   "source": [
    "## Neural Network:\n",
    "**The data is now passed through a NN classifier which ws a Multi Layer Perceptron (MLP). The neural network has difficulty converging before the maximum number of iterations allowed if the data is not normalized. Multi-layer Perceptron is sensitive to feature scaling, so I scaled the data. I also applied the same scaling to the test set for meaningful results. StandardScaler was used for standardization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "atp5m8Ws7H1x",
    "outputId": "0588b39b-d28f-4d46-c301-983cfa0eae69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "\n",
    "scaler.fit(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGGsI1F_8hNs"
   },
   "outputs": [],
   "source": [
    "#Applying the transformations to the data \n",
    "x_train = scaler.transform(X_train_res)\n",
    "\n",
    "x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5siuW0EM5bP"
   },
   "source": [
    "**Training the model using Estimator Objects:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2N5HPf8586qN"
   },
   "outputs": [],
   "source": [
    "#Importing MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Setting the number of hidden layers(3) and the sizes of the neurons at 21 each for the 21 input features\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(21,21,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "-svxfTL19mUI",
    "outputId": "94785db5-df01-440b-8319-dab7fb4ca2a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(21, 21, 21), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ffitting the processed and scaled data with the MLP classifier\n",
    "mlp.fit(x_train,Y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJFTn1EPOfD8"
   },
   "source": [
    "### Scoring the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ssqPrizIzyDN",
    "outputId": "8e77b181-518d-486e-917e-8b8f0fdf6641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.04 %\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train, Y_train_res)\n",
    "\n",
    "acc_mlp = round(mlp.score(x_train, Y_train_res) * 100, 2)\n",
    "print(round(acc_mlp,2,), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3SnlmbyOpoX"
   },
   "source": [
    "**The training set scored 81.04% which means it's not overfitting but might be slightly underfitting. This will be decided later on.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "eBbSwWsn4l7q",
    "outputId": "4ab64ca4-c882-4ba6-b79b-e19bb48e0d06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68242, 12417],\n",
       "       [22177, 58482]])"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for the training set\n",
    "predictions = cross_val_predict(mlp, x_train, Y_train_res, cv=3)\n",
    "confusion_matrix(Y_train_res, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "DzLgVEk09kdh",
    "outputId": "1d381be3-3574-4b7b-e63a-3d9f5bb00a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80     80659\n",
      "           1       0.82      0.73      0.77     80659\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    161318\n",
      "   macro avg       0.79      0.79      0.79    161318\n",
      "weighted avg       0.79      0.79      0.79    161318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for the training set \n",
    "print(classification_report(Y_train_res,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "DqCF4ZGCwsJA",
    "outputId": "b0c4e688-658e-4033-f53b-cc6c8b3436d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.80188445 0.79308207 0.79134639 0.80275229 0.80399207 0.80039673\n",
      " 0.7983511  0.79264815 0.8000248  0.80588965]\n",
      "Mean: 0.7990367702658892\n",
      "Standard Deviation: 0.004818110213421101\n"
     ]
    }
   ],
   "source": [
    "#Cross validation score for the NN\n",
    "scores = cross_val_score(mlp, x_train, Y_train_res, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDZcIwHvPtc-"
   },
   "source": [
    "**This shows an average of 79.9% and varies slightly by 0.48%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VM5rfDJ-Yy4"
   },
   "outputs": [],
   "source": [
    "# Predictions using the fitted model\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "_Pu75E5Q-ksH",
    "outputId": "ee633a87-bbc3-403d-f122-02b57250a93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29862  4783]\n",
      " [ 3477  9757]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for the predictions\n",
    "print(confusion_matrix(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "Jbyhq96P-37m",
    "outputId": "0809c660-b4e0-4fc7-97ea-9b207e180d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88     34645\n",
      "           1       0.67      0.74      0.70     13234\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     47879\n",
      "   macro avg       0.78      0.80      0.79     47879\n",
      "weighted avg       0.83      0.83      0.83     47879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for the predictions\n",
    "print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7N9ly56cNxMY",
    "outputId": "2d140b86-d7fa-4e84-bf90-b1ba9e01425f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.73 %\n"
     ]
    }
   ],
   "source": [
    "#Scoring the MLP on the testing dat \n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train, Y_train_res)\n",
    "\n",
    "acc_mlp = round(mlp.score(x_test, Y_test) * 100, 2)\n",
    "print(round(acc_mlp,2,), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDbIdxEEQ2eX"
   },
   "source": [
    "**The MLP scored 81.73% which is better than that of the training data. This will suggest that the MLP is underfitting slightly. It also scored a  much better classification report.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ov1IfO43RMjC"
   },
   "source": [
    "### Hyperparameter tuning of the Multi-Layer perceptron Classifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "bhsbU2zkJQ-R",
    "outputId": "885673d8-250c-45c0-9434-8411bcb6c73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (25, 20, 25), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.785 (+/-0.034) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (25, 20, 25), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#Parameters are specified and again less are used to reduce running time.\n",
    "mlp = MLPClassifier(max_iter=200)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(25,20,25)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001],\n",
    "    'learning_rate': ['constant'],\n",
    "}\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(x_train, Y_train_res)\n",
    "\n",
    "# Best parameter set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "DtZ6YFOcVrdr",
    "outputId": "17e1b7b9-1e35-4d94-c00e-31777ad5b837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88     34645\n",
      "           1       0.66      0.75      0.70     13234\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     47879\n",
      "   macro avg       0.78      0.80      0.79     47879\n",
      "weighted avg       0.83      0.82      0.83     47879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#These parameters are then used to predict x test\n",
    "y_pred = clf.predict(x_test)\n",
    "#Classification report for the hyper parameter tuned NN\n",
    "print('Results on the test set:')\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoBopzjIS2JT"
   },
   "source": [
    "**These results are very similar to the non-grid searched NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lQZpCkZlFOWx",
    "outputId": "ab3b6068-e576-4ba9-d14c-f774aa45dbb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.46 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the GridSearched NN on the testing set\n",
    "acc_mlp = round(clf.score(x_test, Y_test) * 100, 2)\n",
    "print((acc_mlp), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V74g9grcTU21"
   },
   "source": [
    "**The Grid search had better results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yx_Jb7jeTir8"
   },
   "source": [
    "## Final Verdict:\n",
    "Both classifiers did well relatively but the title of better classifier would have to be given to the Random Forest.\n",
    "This is because when hyperparameters were tuned,\n",
    "\n",
    "1) It had a better accuracy on the testing set after hyper-parameter tuning which was 83.42% compared with NN's 82.46%.\n",
    "\n",
    "2) RF had a better cross validation mean of 85.2% compared with NN's CV's score of 79.9%\n",
    "\n",
    "3) It had a slightly better precision, recall and F1 score.\n",
    "\n",
    "At  training level, the RF overfitted the training set with an accuracy of about 99.5% while the NN underfitted slightly with an accuracy score of 81.04%.\n",
    "\n",
    "At testing level, the NN had a better accuracy compared with the RF and this was shown on the confusion matrix for each model. NN had less False positives and False Negatives. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Arise_Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
